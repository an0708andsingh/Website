<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Unit 6 Quiz - NPTEL Linear Algebra</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <div class="quiz-container">
    <h1>Unit 6: Underdetermined Systems Quiz</h1>
    <form id="quizForm">
      <div id="question-list"></div>
      <button type="button" onclick="submitQuiz()">Submit Quiz</button>
    </form>
    <div id="result"></div>
  </div>

  <script>
    const questions = [
      {
        q: "1. An underdetermined system of linear equations has:",
        options: ["A. A unique solution", "B. No solution", "C. Fewer equations than unknowns", "D. Equal number of equations and unknowns"],
        answer: "C"
      },
      {
        q: "2. The least-norm solution to an underdetermined system minimizes:",
        options: ["A. The number of non-zero entries in the solution", "B. The error in predictions", "C. The Euclidean norm ∥ x ∥² subject to Ax = b", "D. The determinant of the coefficient matrix"],
        answer: "C"
      },
      {
        q: "3. In sparse recovery, the goal is to:",
        options: ["A. Maximize the number of non-zero elements", "B. Find the solution with the fewest non-zero entries that satisfies the system", "C. Increase the condition number of the matrix", "D. Compute eigenvalues of the matrix"],
        answer: "B"
      },
      {
        q: "4. Which optimization technique is commonly used for sparse solutions in compressed sensing?",
        options: ["A. L2 norm minimization", "B. Principal Component Analysis", "C. L1 norm minimization", "D. Singular value decomposition"],
        answer: "C"
      },
      {
        q: "5. Dictionary learning in signal processing is used to:",
        options: ["A. Reduce data variance", "B. Identify principal components", "C. Learn a set of basis vectors for sparse representation of data", "D. Perform matrix inversion efficiently"],
        answer: "C"
      },
      {
        q: "6. In sparse coding, each input vector is approximated as:",
        options: ["A. A sum of random projections", "B. A sparse linear combination of dictionary atoms", "C. An eigenvector of the data matrix", "D. A linear combination with full support"],
        answer: "B"
      },
      {
        q: "7. The inverse eigenvalue problem seeks to:",
        options: ["A. Compute eigenvalues of a given matrix", "B. Find a matrix that has a given set of eigenvalues", "C. Minimize eigenvectors’ angles", "D. Determine the number of principal components"],
        answer: "B"
      },
      {
        q: "8. In the context of Markov chains, a stationary distribution π satisfies:",
        options: ["A) π = P πᵀ", "B) πᵀ = πᵀP", "C) π P = π", "D) π = π"],
        answer: "C"
      },
      {
        q: "9. Given a stationary distribution π, a valid transition matrix P must satisfy:",
        options: ["A. P is symmetric", "B. P is stochastic and π P = π", "C. P is invertible and sparse", "D. P has all negative entries"],
        answer: "B"
      },
      {
        q: "10. One approach to constructing a transition matrix P from a stationary distribution π is:",
        options: ["A) P = π πᵀ", "B) Use P = D⁻¹A, where A is a symmetric matrix and D is a diagonal matrix with π", "C) Apply PCA on π", "D. Minimize the spectral norm of π"],
        answer: "B"
      },
      {
        q: "11. Which method is typically used to solve an underdetermined system Ax=b with many solutions?",
        options: ["A. Gradient descent", "B. Moore-Penrose pseudoinverse", "C. Eigenvalue decomposition", "D. LU decomposition"],
        answer: "B"
      },
      {
        q: "12. In compressed sensing, which property helps in exact sparse recovery?",
        options: ["A. Diagonal dominance", "B. Restricted Isometry Property (RIP)", "C. Toeplitz structure", "D. Low rank"],
        answer: "B"
      },
      {
        q: "13. Which norm is not typically used to promote sparsity?",
        options: ["A. L0 norm", "B. L1 norm", "C. L2 norm", "D. Elastic net (L1 + L2)"],
        answer: "C"
      },
      {
        q: "14. In dictionary learning, the optimization alternates between:",
        options: ["A. Data whitening and clustering", "B. Matrix factorization and eigenvalue updates", "C. Updating dictionary atoms and sparse coefficients", "D. Reducing rank and dimension"],
        answer: "C"
      },
      {
        q: "15. In the inverse eigenvalue problem, which is generally specified?",
        options: ["A. Only the eigenvectors", "B. A target matrix and its inverse", "C. A set of eigenvalues and a structure for the matrix", "D. The trace of the matrix"],
        answer: "C"
      },
      {
        q: "16. Which of the following is not a valid constraint on a stochastic matrix?",
        options: ["A. All rows sum to one", "B. All elements are non-negative", "C. The matrix is symmetric", "D. It represents transition probabilities"],
        answer: "C"
      },
      {
        q: "17. The Markov chain property that makes it memoryless is:",
        options: ["A. Reversibility", "B. Stationarity", "C. Markov property", "D. Time-homogeneity"],
        answer: "C"
      },
      {
        q: "18. The stationary distribution of a finite irreducible, aperiodic Markov chain:",
        options: ["A. Does not exist", "B. Depends on initial state", "C. Is unique and independent of the starting distribution", "D. Changes with time"],
        answer: "C"
      },
      {
        q: "19. Which application is best modeled using sparse coding?",
        options: ["A. Image classification using CNNs", "B. Topic modeling in documents", "C. Image denoising or compression using learned basis", "D. Computing exact solutions to linear systems"],
        answer: "C"
      },
      {
        q: "20. If multiple solutions exist in Ax=b, which is preferred?",
        options: ["A. Highest norm", "B. Smallest L1 norm", "C. Smallest L2 norm", "D. Highest determinant"],
        answer: "C"
      },
      {
        q: "21. Sparse coding is best defined as:",
        options: ["A. Mapping high-dimensional data to labels", "B. Using many atoms", "C. Expressing data with few active coefficients", "D. Projecting onto orthogonal axes"],
        answer: "C"
      },
      {
        q: "22. The L0 norm counts:",
        options: ["A. Number of non-zero entries", "B. Sum of entries", "C. Vector length", "D. Square of Euclidean norm"],
        answer: "A"
      },
      {
        q: "23. The “dictionary” in dictionary learning is:",
        options: ["A. Hyperparameters", "B. Basis vector matrix", "C. Lookup table", "D. Matrix of eigenvectors"],
        answer: "B"
      },
      {
        q: "24. Inverse eigenvalue problem is essential when:",
        options: ["A. Desired dynamic behavior is known", "B. Find eigenvectors", "C. Reduce dimensionality", "D. Gaussian elimination"],
        answer: "A"
      },
      {
        q: "25. Which is not a sparse recovery objective?",
        options: ["A. Minimize active coefficients", "B. Exact reconstruction", "C. Minimize L2 norm for sparsity", "D. Minimize L1 norm"],
        answer: "C"
      },
      {
        q: "26. Unique stationary distribution ensured by:",
        options: ["A. Diagonalization", "B. Reversibility", "C. Irreducibility & aperiodicity", "D. Non-negative eigenvalues"],
        answer: "C"
      },
      {
        q: "27. Constructing a Markov chain from π involves:",
        options: ["A. Making chain symmetric", "B. Solving inverse eigenvalue problem", "C. Designing P such that πP = π", "D. Real eigenvalues"],
        answer: "C"
      },
      {
        q: "28. Sparsity constraint encourages:",
        options: ["A. Large values", "B. Many zeros", "C. Positive definite matrix", "D. Same subspace"],
        answer: "B"
      },
      {
        q: "29. Sparse representation is useful for:",
        options: ["A. Matrix multiplication", "B. Sorting", "C. Face recognition", "D. PageRank"],
        answer: "C"
      },
      {
        q: "30. In sparse coding, an “atom” is:",
        options: ["A. Scalar multiplier", "B. Row in data", "C. Basis vector", "D. Sample input"],
        answer: "C"
      },
      {
        q: "31. Common sparse solution algorithm is:",
        options: ["A. K-means", "B. LASSO", "C. Ridge regression", "D. Gaussian elimination"],
        answer: "B"
      },
      {
        q: "32. A challenge in inverse eigenvalue problem is:",
        options: ["A. Too few eigenvalues", "B. Non-unique solution", "C. Structural constraints", "D. Only diagonal matrices"],
        answer: "C"
      },
      {
        q: "33. P is stochastic if:",
        options: ["A. Columns sum to 1", "B. Rows sum to 1", "C. Determinant is 1", "D. Symmetric eigenvalues"],
        answer: "B"
      },
      {
        q: "34. Multiple stationary distributions occur when:",
        options: ["A. Doubly stochastic", "B. Chain is reducible", "C. Chain is aperiodic", "D. Diagonal matrix"],
        answer: "B"
      },
      {
        q: "35. In compressed sensing, measurements are:",
        options: ["A. More than variables", "B. Equal to variables", "C. Fewer than variables", "D. Unrelated"],
        answer: "C"
      },
      {
        q: "36. Not required in dictionary learning:",
        options: ["A. Overcompleteness", "B. Orthogonality", "C. Sparse coefficients", "D. Signal reconstruction"],
        answer: "B"
      },
      {
        q: "37. Symmetric matrix ⇒ eigenvalues must be:",
        options: ["A. Positive", "B. Negative", "C. Real", "D. Complex"],
        answer: "C"
      },
      {
        q: "38. Type of matrix for Markov transition matrix P:",
        options: ["A. Identity", "B. Stochastic", "C. Diagonal", "D. Symmetric"],
        answer: "B"
      },
      {
        q: "39. A stationary distribution is:",
        options: ["A. Changing every step", "B. Converged distribution", "C. Maximizing entropy", "D. Initial distribution"],
        answer: "B"
      },
      {
        q: "40. To construct a Markov chain with π, P must:",
        options: ["A. Rows equal π", "B. Columns sum to 0", "C. Rows sum to 1", "D. All eigenvalues zero"],
        answer: "C"
      }
    ];

    function renderQuestions() {
      const container = document.getElementById("question-list");
      questions.forEach((item, index) => {
        const div = document.createElement("div");
        div.className = "question";
        div.innerHTML = `<p>${item.q}</p>` +
          item.options.map(opt => `
            <label>
              <input type="radio" name="q${index + 1}" value="${opt.charAt(0)}"> ${opt}
            </label>`).join("");
        container.appendChild(div);
      });
    }

    function submitQuiz() {
      let score = 0;
      questions.forEach((item, index) => {
        const selected = document.querySelector(`input[name="q${index + 1}"]:checked`);
        if (selected && selected.value === item.answer) {
          score++;
        }
      });
      document.getElementById("result").textContent = `✅ You scored ${score} out of ${questions.length}`;
    }

    renderQuestions();
  </script>
</body>
</html>
